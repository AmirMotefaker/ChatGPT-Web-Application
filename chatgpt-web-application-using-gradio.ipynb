{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/chatgpt-web-application-using-gradio?scriptVersionId=122377160\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Introduction\n\n- ChatGPT (Chat Generative Pre-trained Transformer) is an AI-powered chatbot created by OpenAI that enables users to have highly sophisticated, human-like conversations. The language model is capable of answering questions and assist in various tasks, including writing emails, essays, and code. Due to its dialogue design, ChatGPT is capable of answering follow-up questions, acknowledging errors, questioning incorrect assumptions, and declining inappropriate requests.\n\n- The ChatGPT model was fine-tuned from a model in the GPT-3.5 series, which completed its training in early 2022. The ChatGPT as well as the related GPT-3.5 models were trained on a high-performance Azure AI supercomputing infrastructure.\n\n- While ChatGPT possesses many strengths, being a generalized model, it may not always be the most effective solution for narrower, more specialized topics with limited training data available. Moreover, the dialog interface has not yet been made available by OpenAI for businesses to integrate.\n\n- The purpose of this article is to demonstrate the creation of a chatbot interface, similar to ChatGPT, by integrating OpenAI GPT-3 models with a custom-built Gradio interface.\n\n# GPT-3 \n\n- In 2020, the Generative Pre-trained Transformer 3 (GPT-3) was introduced as an autoregressive language model capable to generate high-quality text that resembles human writing. The GPT-3 is the third generation of the GPT language models made available by OpenAI.\n\n- By providing an initial prompt as input, GPT-3 has the ability to produce a continuation of the text that follows the style and structure of the input prompt. The model is capable of performing a range of tasks, including but not limited to, text classification, question answering, text generation, text summarization, named-entity recognition, and language translation.\n\n# Python implementation\n\n- To access OpenAI’s services, the first step is to acquire an API token. If you don’t have an account yet, you can register for a free trial by visiting their [signup page](https://platform.openai.com/signup). Once you have an account, go to the top right corner of the page and click “Manage Account”. From there, navigate to “API Keys” and create a new secret key.\n\n- Install the OpenAI Python library using pip: pip install openai, then create a new Jupyter notebook file and paste the following code snippet to a new cell.","metadata":{}},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-03-05T09:00:53.304274Z","iopub.execute_input":"2023-03-05T09:00:53.305089Z","iopub.status.idle":"2023-03-05T09:01:04.626653Z","shell.execute_reply.started":"2023-03-05T09:00:53.30502Z","shell.execute_reply":"2023-03-05T09:01:04.624754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import openai\n# openai.api_key = sk_token # your token goes here\nopenai.api_key = \"YOUR SECRET KEY\"\n\ndef get_model_reply(query, context=[]):\n    # combines the new question with a previous context\n    context += [query]\n    \n    # given the most recent context (4096 characters)\n    # continue the text up to 2048 tokens ~ 8192 charaters\n    completion = openai.Completion.create(\n        engine='text-davinci-003', # one of the most capable models available\n        prompt='\\n\\n'.join(context)[:4096],\n        max_tokens = 2048,\n        temperature = 0.0, # Lower values make the response more deterministic\n    )\n    \n    # append response to context\n    response = completion.choices[0].text.strip('\\n')\n    context += [response]\n    \n    # list of (user, bot) responses. We will use this format later\n    responses = [(u,b) for u,b in zip(context[::2], context[1::2])]\n    \n    return responses, context","metadata":{"execution":{"iopub.status.busy":"2023-03-05T09:01:04.634592Z","iopub.execute_input":"2023-03-05T09:01:04.634958Z","iopub.status.idle":"2023-03-05T09:01:04.733765Z","shell.execute_reply.started":"2023-03-05T09:01:04.634922Z","shell.execute_reply":"2023-03-05T09:01:04.732372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- To test the GPT-3 auto-complete simply call the function with a query and no context. In the example below, GPT-3 was asked “Which is the largest country by area in the world?” and the model correctly returned Russia as the largest country by area, as well as the approximate total area.","metadata":{}},{"cell_type":"code","source":"query = 'Which is the largest country by area in the world?'\nresponses, context = get_model_reply(query, context=[])\n\nprint('<USER> ' + responses[-1][0])\nprint('<BOT> ' + responses[-1][1])\n\n# OUTPUT:\n#\n# <USER> Which is the largest country by area in the world?\n# <BOT> The largest country by area in the world is Russia, with a total area of 17,098,242 square kilometers (6,601,668 square miles).","metadata":{"execution":{"iopub.status.busy":"2023-03-05T09:01:04.735264Z","iopub.execute_input":"2023-03-05T09:01:04.736075Z","iopub.status.idle":"2023-03-05T09:01:06.343564Z","shell.execute_reply.started":"2023-03-05T09:01:04.736019Z","shell.execute_reply":"2023-03-05T09:01:06.342285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- One way to evaluate the model’s ability to handle follow-up questions is to invoke it again while providing the previous context. As demonstrated in the following example, when asked “Which countries share a border with it?”, referring to Russia, GPT-3 successfully recognized the topic and accurately provided the answer by listing the 14 neighboring countries.","metadata":{}},{"cell_type":"code","source":"query = 'With which countries does it share a border?'\nresponses, context = get_model_reply(query, context=context)\n\nprint('<USER> ' + responses[-1][0])\nprint('<BOT> ' + responses[-1][1])\n\n# OUTPUT:\n#\n# <USER> With which countries does it share a border?\n# <BOT> Russia shares a border with the following countries: Norway, Finland, Estonia, Latvia, Lithuania, Poland, Belarus, Ukraine, Georgia, Azerbaijan, Kazakhstan, Mongolia, China, North Korea, and Lithuania.","metadata":{"execution":{"iopub.status.busy":"2023-03-05T09:01:06.346609Z","iopub.execute_input":"2023-03-05T09:01:06.348234Z","iopub.status.idle":"2023-03-05T09:01:07.777824Z","shell.execute_reply.started":"2023-03-05T09:01:06.348172Z","shell.execute_reply":"2023-03-05T09:01:07.77657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradio\n\n- Gradio is an open-source Python library that is used to build machine learning and data science demos and web applications.\n\n- Gradio is an open-source Python library used to build machine learning and data science web applications. Gradio allows developers to create user-friendly and customizable interfaces. Additionally, it enables other users to access the machine-learning models from any location.\n\n- Another interesting aspect of Gradio is that it permits the development and testing of the web application within Jupyter or Google Colab notebooks. This functionality is highly advantageous when evaluating the integration of other modules.","metadata":{}},{"cell_type":"markdown","source":"# Python implementation\n\n- Start by installing the Gradio Python package with pip: pip install gradio.","metadata":{}},{"cell_type":"code","source":"!pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-03-05T09:01:07.779438Z","iopub.execute_input":"2023-03-05T09:01:07.779793Z","iopub.status.idle":"2023-03-05T09:01:19.49253Z","shell.execute_reply.started":"2023-03-05T09:01:07.779755Z","shell.execute_reply":"2023-03-05T09:01:19.491195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gradio as gr\n\n# defines a basic dialog interface using Gradio\nwith gr.Blocks() as dialog_app:\n    chatbot = gr.Chatbot() # dedicated \"chatbot\" component\n    state = gr.State([]) # session state that persists across multiple submits\n    \n    with gr.Row():\n        txt = gr.Textbox(\n            show_label=False, \n            placeholder=\"Enter text and press enter\"\n        ).style(container=False)\n\n    txt.submit(get_model_reply, [txt, state], [chatbot, state])\n\n# launches the app in a new local port\ndialog_app.launch()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T09:01:19.494165Z","iopub.execute_input":"2023-03-05T09:01:19.494557Z","iopub.status.idle":"2023-03-05T09:01:25.917298Z","shell.execute_reply.started":"2023-03-05T09:01:19.494516Z","shell.execute_reply":"2023-03-05T09:01:25.916087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\n- ChatGPT is an AI-powered chatbot created by OpenAI that has the ability to carry out human-like conversations and assist users in various tasks, from writing essays to code. While it may not be the most effective solution for specialized topics, it has impressive dialogue capabilities.","metadata":{}}]}