{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/chatgpt-web-application-using-gradio?scriptVersionId=121099750\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Introduction\n\n- ChatGPT (Chat Generative Pre-trained Transformer) is an AI-powered chatbot created by OpenAI that enables users to have highly sophisticated, human-like conversations. The language model is capable of answering questions and assist in various tasks, including writing emails, essays, and code. Due to its dialogue design, ChatGPT is capable of answering follow-up questions, acknowledging errors, questioning incorrect assumptions, and declining inappropriate requests.\n\n- The ChatGPT model was fine-tuned from a model in the GPT-3.5 series, which completed its training in early 2022. The ChatGPT as well as the related GPT-3.5 models were trained on a high-performance Azure AI supercomputing infrastructure.\n\n- While ChatGPT possesses many strengths, being a generalized model, it may not always be the most effective solution for narrower, more specialized topics with limited training data available. Moreover, the dialog interface has not yet been made available by OpenAI for businesses to integrate.\n\n- The purpose of this article is to demonstrate the creation of a chatbot interface, similar to ChatGPT, by integrating OpenAI GPT-3 models with a custom-built Gradio interface.\n\n# GPT-3 \n\n- In 2020, the Generative Pre-trained Transformer 3 (GPT-3) was introduced as an autoregressive language model capable to generate high-quality text that resembles human writing. The GPT-3 is the third generation of the GPT language models made available by OpenAI.\n\n- By providing an initial prompt as input, GPT-3 has the ability to produce a continuation of the text that follows the style and structure of the input prompt. The model is capable of performing a range of tasks, including but not limited to, text classification, question answering, text generation, text summarization, named-entity recognition, and language translation.\n\n# Python implementation\n\n- To access OpenAI’s services, the first step is to acquire an API token. If you don’t have an account yet, you can register for a free trial by visiting their [signup page](https://platform.openai.com/signup). Once you have an account, go to the top right corner of the page and click “Manage Account”. From there, navigate to “API Keys” and create a new secret key.\n\n- Install the OpenAI Python library using pip: pip install openai, then create a new Jupyter notebook file and paste the following code snippet to a new cell.","metadata":{}},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-03-04T05:45:05.468047Z","iopub.execute_input":"2023-03-04T05:45:05.468433Z","iopub.status.idle":"2023-03-04T05:45:19.108163Z","shell.execute_reply.started":"2023-03-04T05:45:05.468398Z","shell.execute_reply":"2023-03-04T05:45:19.106587Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m534.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: openai\nSuccessfully installed openai-0.27.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import openai\n# openai.api_key = sk_token # your token goes here\nopenai.api_key = \"YOUR SECRET KEY\"\n\ndef get_model_reply(query, context=[]):\n    # combines the new question with a previous context\n    context += [query]\n    \n    # given the most recent context (4096 characters)\n    # continue the text up to 2048 tokens ~ 8192 charaters\n    completion = openai.Completion.create(\n        engine='text-davinci-003', # one of the most capable models available\n        prompt='\\n\\n'.join(context)[:4096],\n        max_tokens = 2048,\n        temperature = 0.0, # Lower values make the response more deterministic\n    )\n    \n    # append response to context\n    response = completion.choices[0].text.strip('\\n')\n    context += [response]\n    \n    # list of (user, bot) responses. We will use this format later\n    responses = [(u,b) for u,b in zip(context[::2], context[1::2])]\n    \n    return responses, context","metadata":{"execution":{"iopub.status.busy":"2023-03-04T06:00:51.218132Z","iopub.execute_input":"2023-03-04T06:00:51.218576Z","iopub.status.idle":"2023-03-04T06:00:51.226528Z","shell.execute_reply.started":"2023-03-04T06:00:51.218533Z","shell.execute_reply":"2023-03-04T06:00:51.225607Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"- To test the GPT-3 auto-complete simply call the function with a query and no context. In the example below, GPT-3 was asked “Which is the largest country by area in the world?” and the model correctly returned Russia as the largest country by area, as well as the approximate total area.","metadata":{}},{"cell_type":"code","source":"query = 'Which is the largest country by area in the world?'\nresponses, context = get_model_reply(query, context=[])\n\nprint('<USER> ' + responses[-1][0])\nprint('<BOT> ' + responses[-1][1])\n\n# OUTPUT:\n#\n# <USER> Which is the largest country by area in the world?\n# <BOT> The largest country by area in the world is Russia, with a total area of 17,098,242 square kilometers (6,601,668 square miles).","metadata":{"execution":{"iopub.status.busy":"2023-03-04T06:03:07.441237Z","iopub.execute_input":"2023-03-04T06:03:07.441688Z","iopub.status.idle":"2023-03-04T06:03:09.724805Z","shell.execute_reply.started":"2023-03-04T06:03:07.441645Z","shell.execute_reply":"2023-03-04T06:03:09.723588Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<USER> Which is the largest country by area in the world?\n<BOT> The largest country by area in the world is Russia, with a total area of 17,098,242 square kilometers (6,601,668 square miles).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- One way to evaluate the model’s ability to handle follow-up questions is to invoke it again while providing the previous context. As demonstrated in the following example, when asked “Which countries share a border with it?”, referring to Russia, GPT-3 successfully recognized the topic and accurately provided the answer by listing the 14 neighboring countries.","metadata":{}},{"cell_type":"code","source":"query = 'With which countries does it share a border?'\nresponses, context = get_model_reply(query, context=context)\n\nprint('<USER> ' + responses[-1][0])\nprint('<BOT> ' + responses[-1][1])\n\n# OUTPUT:\n#\n# <USER> With which countries does it share a border?\n# <BOT> Russia shares a border with the following countries: Norway, Finland, Estonia, Latvia, Lithuania, Poland, Belarus, Ukraine, Georgia, Azerbaijan, Kazakhstan, Mongolia, China, North Korea, and Lithuania.","metadata":{"execution":{"iopub.status.busy":"2023-03-04T06:07:21.656312Z","iopub.execute_input":"2023-03-04T06:07:21.656713Z","iopub.status.idle":"2023-03-04T06:07:24.312936Z","shell.execute_reply.started":"2023-03-04T06:07:21.656676Z","shell.execute_reply":"2023-03-04T06:07:24.311582Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<USER> With which countries does it share a border?\n<BOT> Russia shares a border with the following countries: Norway, Finland, Estonia, Latvia, Lithuania, Poland, Belarus, Ukraine, Georgia, Azerbaijan, Kazakhstan, Mongolia, China, North Korea, and Lithuania.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Gradio\n\n- Gradio is an open-source Python library that is used to build machine learning and data science demos and web applications.\n\n- Gradio is an open-source Python library used to build machine learning and data science web applications. Gradio allows developers to create user-friendly and customizable interfaces. Additionally, it enables other users to access the machine-learning models from any location.\n\n- Another interesting aspect of Gradio is that it permits the development and testing of the web application within Jupyter or Google Colab notebooks. This functionality is highly advantageous when evaluating the integration of other modules.","metadata":{}},{"cell_type":"markdown","source":"# Python implementation\n\n- Start by installing the Gradio Python package with pip: pip install gradio.","metadata":{}}]}