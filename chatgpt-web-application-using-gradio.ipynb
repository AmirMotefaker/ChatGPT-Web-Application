{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/chatgpt-web-application-using-gradio?scriptVersionId=121100140\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Introduction\n\n- ChatGPT (Chat Generative Pre-trained Transformer) is an AI-powered chatbot created by OpenAI that enables users to have highly sophisticated, human-like conversations. The language model is capable of answering questions and assist in various tasks, including writing emails, essays, and code. Due to its dialogue design, ChatGPT is capable of answering follow-up questions, acknowledging errors, questioning incorrect assumptions, and declining inappropriate requests.\n\n- The ChatGPT model was fine-tuned from a model in the GPT-3.5 series, which completed its training in early 2022. The ChatGPT as well as the related GPT-3.5 models were trained on a high-performance Azure AI supercomputing infrastructure.\n\n- While ChatGPT possesses many strengths, being a generalized model, it may not always be the most effective solution for narrower, more specialized topics with limited training data available. Moreover, the dialog interface has not yet been made available by OpenAI for businesses to integrate.\n\n- The purpose of this article is to demonstrate the creation of a chatbot interface, similar to ChatGPT, by integrating OpenAI GPT-3 models with a custom-built Gradio interface.\n\n# GPT-3 \n\n- In 2020, the Generative Pre-trained Transformer 3 (GPT-3) was introduced as an autoregressive language model capable to generate high-quality text that resembles human writing. The GPT-3 is the third generation of the GPT language models made available by OpenAI.\n\n- By providing an initial prompt as input, GPT-3 has the ability to produce a continuation of the text that follows the style and structure of the input prompt. The model is capable of performing a range of tasks, including but not limited to, text classification, question answering, text generation, text summarization, named-entity recognition, and language translation.\n\n# Python implementation\n\n- To access OpenAI’s services, the first step is to acquire an API token. If you don’t have an account yet, you can register for a free trial by visiting their [signup page](https://platform.openai.com/signup). Once you have an account, go to the top right corner of the page and click “Manage Account”. From there, navigate to “API Keys” and create a new secret key.\n\n- Install the OpenAI Python library using pip: pip install openai, then create a new Jupyter notebook file and paste the following code snippet to a new cell.","metadata":{}},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-03-04T05:45:05.468047Z","iopub.execute_input":"2023-03-04T05:45:05.468433Z","iopub.status.idle":"2023-03-04T05:45:19.108163Z","shell.execute_reply.started":"2023-03-04T05:45:05.468398Z","shell.execute_reply":"2023-03-04T05:45:19.106587Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m534.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: openai\nSuccessfully installed openai-0.27.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import openai\n# openai.api_key = sk_token # your token goes here\nopenai.api_key = \"YOUR SECRET KEY\"\n\ndef get_model_reply(query, context=[]):\n    # combines the new question with a previous context\n    context += [query]\n    \n    # given the most recent context (4096 characters)\n    # continue the text up to 2048 tokens ~ 8192 charaters\n    completion = openai.Completion.create(\n        engine='text-davinci-003', # one of the most capable models available\n        prompt='\\n\\n'.join(context)[:4096],\n        max_tokens = 2048,\n        temperature = 0.0, # Lower values make the response more deterministic\n    )\n    \n    # append response to context\n    response = completion.choices[0].text.strip('\\n')\n    context += [response]\n    \n    # list of (user, bot) responses. We will use this format later\n    responses = [(u,b) for u,b in zip(context[::2], context[1::2])]\n    \n    return responses, context","metadata":{"execution":{"iopub.status.busy":"2023-03-04T06:00:51.218132Z","iopub.execute_input":"2023-03-04T06:00:51.218576Z","iopub.status.idle":"2023-03-04T06:00:51.226528Z","shell.execute_reply.started":"2023-03-04T06:00:51.218533Z","shell.execute_reply":"2023-03-04T06:00:51.225607Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"- To test the GPT-3 auto-complete simply call the function with a query and no context. In the example below, GPT-3 was asked “Which is the largest country by area in the world?” and the model correctly returned Russia as the largest country by area, as well as the approximate total area.","metadata":{}},{"cell_type":"code","source":"query = 'Which is the largest country by area in the world?'\nresponses, context = get_model_reply(query, context=[])\n\nprint('<USER> ' + responses[-1][0])\nprint('<BOT> ' + responses[-1][1])\n\n# OUTPUT:\n#\n# <USER> Which is the largest country by area in the world?\n# <BOT> The largest country by area in the world is Russia, with a total area of 17,098,242 square kilometers (6,601,668 square miles).","metadata":{"execution":{"iopub.status.busy":"2023-03-04T06:03:07.441237Z","iopub.execute_input":"2023-03-04T06:03:07.441688Z","iopub.status.idle":"2023-03-04T06:03:09.724805Z","shell.execute_reply.started":"2023-03-04T06:03:07.441645Z","shell.execute_reply":"2023-03-04T06:03:09.723588Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<USER> Which is the largest country by area in the world?\n<BOT> The largest country by area in the world is Russia, with a total area of 17,098,242 square kilometers (6,601,668 square miles).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- One way to evaluate the model’s ability to handle follow-up questions is to invoke it again while providing the previous context. As demonstrated in the following example, when asked “Which countries share a border with it?”, referring to Russia, GPT-3 successfully recognized the topic and accurately provided the answer by listing the 14 neighboring countries.","metadata":{}},{"cell_type":"code","source":"query = 'With which countries does it share a border?'\nresponses, context = get_model_reply(query, context=context)\n\nprint('<USER> ' + responses[-1][0])\nprint('<BOT> ' + responses[-1][1])\n\n# OUTPUT:\n#\n# <USER> With which countries does it share a border?\n# <BOT> Russia shares a border with the following countries: Norway, Finland, Estonia, Latvia, Lithuania, Poland, Belarus, Ukraine, Georgia, Azerbaijan, Kazakhstan, Mongolia, China, North Korea, and Lithuania.","metadata":{"execution":{"iopub.status.busy":"2023-03-04T06:07:21.656312Z","iopub.execute_input":"2023-03-04T06:07:21.656713Z","iopub.status.idle":"2023-03-04T06:07:24.312936Z","shell.execute_reply.started":"2023-03-04T06:07:21.656676Z","shell.execute_reply":"2023-03-04T06:07:24.311582Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<USER> With which countries does it share a border?\n<BOT> Russia shares a border with the following countries: Norway, Finland, Estonia, Latvia, Lithuania, Poland, Belarus, Ukraine, Georgia, Azerbaijan, Kazakhstan, Mongolia, China, North Korea, and Lithuania.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Gradio\n\n- Gradio is an open-source Python library that is used to build machine learning and data science demos and web applications.\n\n- Gradio is an open-source Python library used to build machine learning and data science web applications. Gradio allows developers to create user-friendly and customizable interfaces. Additionally, it enables other users to access the machine-learning models from any location.\n\n- Another interesting aspect of Gradio is that it permits the development and testing of the web application within Jupyter or Google Colab notebooks. This functionality is highly advantageous when evaluating the integration of other modules.","metadata":{}},{"cell_type":"markdown","source":"# Python implementation\n\n- Start by installing the Gradio Python package with pip: pip install gradio.","metadata":{}},{"cell_type":"code","source":"!pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-03-05T08:51:59.176753Z","iopub.execute_input":"2023-03-05T08:51:59.177156Z","iopub.status.idle":"2023-03-05T08:52:16.643587Z","shell.execute_reply.started":"2023-03-05T08:51:59.17712Z","shell.execute_reply":"2023-03-05T08:52:16.642455Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-3.20.0-py3-none-any.whl (14.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (2.1.0)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.7/site-packages (from gradio) (3.8.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from gradio) (1.3.5)\nCollecting python-multipart\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from gradio) (4.4.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from gradio) (6.0)\nCollecting aiofiles\n  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.7/site-packages (from gradio) (3.17)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.7/site-packages (from gradio) (0.89.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from gradio) (3.5.3)\nCollecting httpx\n  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from gradio) (2023.1.0)\nRequirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (4.2.2)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.7/site-packages (from gradio) (2.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from gradio) (1.21.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from gradio) (3.8.3)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from gradio) (1.10.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from gradio) (9.4.0)\nRequirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (10.4)\nCollecting ffmpy\n  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: mdit-py-plugins<=0.3.3 in /opt/conda/lib/python3.7/site-packages (from gradio) (0.3.3)\nRequirement already satisfied: uvicorn in /opt/conda/lib/python3.7/site-packages (from gradio) (0.20.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gradio) (2.28.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (0.11.2)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (0.4)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\nCollecting linkify-it-py~=1.0\n  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio) (2022.7.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio) (2.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.3.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (22.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.8.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (6.0.4)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (2.1.1)\nRequirement already satisfied: starlette==0.22.0 in /opt/conda/lib/python3.7/site-packages (from fastapi->gradio) (0.22.0)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from starlette==0.22.0->fastapi->gradio) (3.6.2)\nCollecting httpcore<0.17.0,>=0.15.0\n  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (2022.12.7)\nCollecting rfc3986[idna2008]<2,>=1.3\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (23.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (4.38.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (0.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gradio) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gradio) (3.4)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio) (0.14.0)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio) (8.1.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.0->uvicorn->gradio) (4.11.4)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.10.2)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (1.3.10)\nCollecting uc-micro-py\n  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.16.0)\nRequirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.11.0)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=dfbc6c555baf13e598c6611e7a254488b60a0c87d06f93fa776e3e3428553c93\n  Stored in directory: /root/.cache/pip/wheels/c0/96/80/1aeaaf27265398a7393b296714b84e51a7d00101f8a665a25a\nSuccessfully built ffmpy\nInstalling collected packages: rfc3986, ffmpy, uc-micro-py, python-multipart, aiofiles, linkify-it-py, httpcore, httpx, gradio\nSuccessfully installed aiofiles-23.1.0 ffmpy-0.3.0 gradio-3.20.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-1.0.3 python-multipart-0.0.6 rfc3986-1.5.0 uc-micro-py-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]}]}