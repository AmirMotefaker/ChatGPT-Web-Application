{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/chatgpt-web-application-using-gradio?scriptVersionId=120999283\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"dc96f115","metadata":{"papermill":{"duration":0.003175,"end_time":"2023-03-04T06:02:27.499804","exception":false,"start_time":"2023-03-04T06:02:27.496629","status":"completed"},"tags":[]},"source":["# Introduction\n","\n","- ChatGPT (Chat Generative Pre-trained Transformer) is an AI-powered chatbot created by OpenAI that enables users to have highly sophisticated, human-like conversations. The language model is capable of answering questions and assist in various tasks, including writing emails, essays, and code. Due to its dialogue design, ChatGPT is capable of answering follow-up questions, acknowledging errors, questioning incorrect assumptions, and declining inappropriate requests.\n","\n","- The ChatGPT model was fine-tuned from a model in the GPT-3.5 series, which completed its training in early 2022. The ChatGPT as well as the related GPT-3.5 models were trained on a high-performance Azure AI supercomputing infrastructure.\n","\n","- While ChatGPT possesses many strengths, being a generalized model, it may not always be the most effective solution for narrower, more specialized topics with limited training data available. Moreover, the dialog interface has not yet been made available by OpenAI for businesses to integrate.\n","\n","- The purpose of this article is to demonstrate the creation of a chatbot interface, similar to ChatGPT, by integrating OpenAI GPT-3 models with a custom-built Gradio interface.\n","\n","# GPT-3 \n","\n","- In 2020, the Generative Pre-trained Transformer 3 (GPT-3) was introduced as an autoregressive language model capable to generate high-quality text that resembles human writing. The GPT-3 is the third generation of the GPT language models made available by OpenAI.\n","\n","- By providing an initial prompt as input, GPT-3 has the ability to produce a continuation of the text that follows the style and structure of the input prompt. The model is capable of performing a range of tasks, including but not limited to, text classification, question answering, text generation, text summarization, named-entity recognition, and language translation.\n","\n","# Python implementation\n","\n","- To access OpenAI’s services, the first step is to acquire an API token. If you don’t have an account yet, you can register for a free trial by visiting their [signup page](https://platform.openai.com/signup). Once you have an account, go to the top right corner of the page and click “Manage Account”. From there, navigate to “API Keys” and create a new secret key.\n","\n","- Install the OpenAI Python library using pip: pip install openai, then create a new Jupyter notebook file and paste the following code snippet to a new cell."]},{"cell_type":"code","execution_count":1,"id":"19dd7ffc","metadata":{"execution":{"iopub.execute_input":"2023-03-04T06:02:27.506406Z","iopub.status.busy":"2023-03-04T06:02:27.506003Z","iopub.status.idle":"2023-03-04T06:02:40.63184Z","shell.execute_reply":"2023-03-04T06:02:40.630305Z"},"papermill":{"duration":13.132715,"end_time":"2023-03-04T06:02:40.634995","exception":false,"start_time":"2023-03-04T06:02:27.50228","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\r\n","  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m773.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\r\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\r\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\r\n","Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\r\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\r\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\r\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\r\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\r\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\r\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\r\n","Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\r\n","Installing collected packages: openai\r\n","Successfully installed openai-0.27.0\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0m"]}],"source":["!pip install openai"]},{"cell_type":"code","execution_count":2,"id":"99336940","metadata":{"execution":{"iopub.execute_input":"2023-03-04T06:02:40.643072Z","iopub.status.busy":"2023-03-04T06:02:40.64263Z","iopub.status.idle":"2023-03-04T06:02:40.736193Z","shell.execute_reply":"2023-03-04T06:02:40.735005Z"},"papermill":{"duration":0.101196,"end_time":"2023-03-04T06:02:40.73914","exception":false,"start_time":"2023-03-04T06:02:40.637944","status":"completed"},"tags":[]},"outputs":[],"source":["import openai\n","# openai.api_key = sk_token # your token goes here\n","openai.api_key = \"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\"\n","\n","def get_model_reply(query, context=[]):\n","    # combines the new question with a previous context\n","    context += [query]\n","    \n","    # given the most recent context (4096 characters)\n","    # continue the text up to 2048 tokens ~ 8192 charaters\n","    completion = openai.Completion.create(\n","        engine='text-davinci-003', # one of the most capable models available\n","        prompt='\\n\\n'.join(context)[:4096],\n","        max_tokens = 2048,\n","        temperature = 0.0, # Lower values make the response more deterministic\n","    )\n","    \n","    # append response to context\n","    response = completion.choices[0].text.strip('\\n')\n","    context += [response]\n","    \n","    # list of (user, bot) responses. We will use this format later\n","    responses = [(u,b) for u,b in zip(context[::2], context[1::2])]\n","    \n","    return responses, context"]},{"cell_type":"markdown","id":"f735c19d","metadata":{"papermill":{"duration":0.002462,"end_time":"2023-03-04T06:02:40.744462","exception":false,"start_time":"2023-03-04T06:02:40.742","status":"completed"},"tags":[]},"source":["- To test the GPT-3 auto-complete simply call the function with a query and no context. In the example below, GPT-3 was asked “Which is the largest country by area in the world?” and the model correctly returned Russia as the largest country by area, as well as the approximate total area."]},{"cell_type":"markdown","id":"e339be9b","metadata":{"papermill":{"duration":0.002309,"end_time":"2023-03-04T06:02:40.749434","exception":false,"start_time":"2023-03-04T06:02:40.747125","status":"completed"},"tags":[]},"source":["# Gradio\n","\n","- Gradio is an open-source Python library that is used to build machine learning and data science demos and web applications."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":25.667404,"end_time":"2023-03-04T06:02:41.4749","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-03-04T06:02:15.807496","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}